{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a29132",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The purpose of this notebook is to provide an example of data cleaning and preparation. In this example, data will be pulled from the Social Security's data set of popular baby names found [here](https://www.ssa.gov/oact/babynames/limits.html). This data will be directly downloaded from the website and organized into one data frame that will be used for a streamlit app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f6820",
   "metadata": {},
   "source": [
    "# Downloading the Data\n",
    "First, we'll pull the data directly from the website found [here](https://www.ssa.gov/oact/babynames/limits.html). At first, I thought this was going to be a simple download using the code below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a381cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Basic download\n",
    "url = \"https://www.ssa.gov/oact/babynames/names.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save to file\n",
    "with open(\"downloaded_file.zip\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Check for errors\n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2253ece",
   "metadata": {},
   "source": [
    "I was wrong. After, many code re-writes it looks like this website detects automated requests and blocks them. I'll try to get around this by using Selenium to simulate being an actual user. NOTE: This should be done with caution. This is a sure way to get kicked off a website if you abuse this power. This happened to me during one of my projects at Booz Allen. I used Selenium to webscrape [matweb](https://matweb.com/) and aggregate material information that I needed for the project. I learned the hard way that your IP address will be black listed if you extract too much data. For this project though, I just want to download one link and that's it. So let's begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "\n",
    "def download_with_selenium_custom_folder(redownload=False):\n",
    "    if redownload==False:\n",
    "        if os.path.exists(os.path.abspath(\"data/names.zip\")):\n",
    "            print(\"File already exists. Skipping download.\")\n",
    "            return\n",
    "            \n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
    "    \n",
    "    # Set download directory\n",
    "    download_dir = os.path.abspath(\"data\")  # Downloads to your project's data folder\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    prefs = {\n",
    "        \"download.default_directory\": download_dir,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    try:\n",
    "        # Visit the main page first\n",
    "        driver.get(\"https://www.ssa.gov/oact/babynames/limits.html\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Find and click the download link\n",
    "        links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        for link in links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href and \"names.zip\" in href:\n",
    "                print(f\"Downloading from: {href}\")\n",
    "                driver.get(href)\n",
    "                time.sleep(5)  # Wait for download to complete\n",
    "                print(f\"File downloaded to: {download_dir}\")\n",
    "                break\n",
    "                \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Run the function\n",
    "download_with_selenium_custom_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14626050",
   "metadata": {},
   "source": [
    "Worked like a charm! Now it's time to restructre the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d00ae5",
   "metadata": {},
   "source": [
    "# Restructuring the Data\n",
    "The data is in a zip folder so let's unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b64b239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file\n",
    "import zipfile\n",
    "zip_file_path = os.path.abspath(\"data/names.zip\")\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c4649",
   "metadata": {},
   "source": [
    "Looks like the data was all stored in text files and there is a ReadMe that states:\n",
    "\n",
    "> **National Data on the relative frequency of given names in the population of\n",
    "> U.S. births where the individual has a Social Security Number**\n",
    "> (Tabulated based on Social Security records as of March 2, 2025)\n",
    "> \n",
    "> For each year of birth YYYY after 1879, we created a comma-delimited file called yobYYYY.txt. Each\n",
    "> record in the individual annual files has the format \"name,sex,number,\" where name is 2 to 15 characters,\n",
    "> sex is M (male) or F (female) and \"number\" is the number of occurrences of the name. Each file is sorted\n",
    "> first on sex and then on number of occurrences in descending order. When there is a tie on the number of\n",
    "> occurrences, names are listed in alphabetical order. This sorting makes it easy to determine a name's rank.\n",
    "> The first record for each sex has rank 1, the second record for each sex has rank 2, and so forth.\n",
    ">\n",
    "> To safeguard privacy, we restrict our list of names to those with at least 5 occurrences\n",
    "\n",
    "Alright, we'll have to read in all of the txt files and aggregate them into one pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7bd825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>total_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135234</th>\n",
       "      <td>Liam</td>\n",
       "      <td>M</td>\n",
       "      <td>22164</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135235</th>\n",
       "      <td>Noah</td>\n",
       "      <td>M</td>\n",
       "      <td>20337</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135236</th>\n",
       "      <td>Oliver</td>\n",
       "      <td>M</td>\n",
       "      <td>15343</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135237</th>\n",
       "      <td>Theodore</td>\n",
       "      <td>M</td>\n",
       "      <td>12011</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135238</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "      <td>11793</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name sex  total_count  year\n",
       "2135234      Liam   M        22164  2024\n",
       "2135235      Noah   M        20337  2024\n",
       "2135236    Oliver   M        15343  2024\n",
       "2135237  Theodore   M        12011  2024\n",
       "2135238     James   M        11793  2024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all of the txt files\n",
    "import pandas as pd\n",
    "\n",
    "# get all of the txt files in the data folder\n",
    "txt_files = [f for f in os.listdir(\"data\") if f.endswith(\".txt\")]\n",
    "\n",
    "# read in all of the txt files\n",
    "df = pd.DataFrame()\n",
    "for file in txt_files:\n",
    "    df_add = pd.read_csv(os.path.join(\"data\", file), header=None)\n",
    "    df_add.columns = [\"name\", \"sex\", \"total_count\"]\n",
    "    df_add[\"year\"] = file.split(\"yob\")[1].split(\".txt\")[0]\n",
    "    df = pd.concat([df, df_add])\n",
    "\n",
    "# convert year to int\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "\n",
    "# drop duplicates and reset index\n",
    "df = df.drop_duplicates(subset=[\"name\", \"sex\", \"year\"])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# sort by year, sex, and total_count\n",
    "df = df.sort_values(by=[\"year\", \"sex\", \"total_count\"], ascending=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b612c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2149477 entries, 2135234 to 941\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   name         object\n",
      " 1   sex          object\n",
      " 2   total_count  int64 \n",
      " 3   year         int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 82.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc89d7e",
   "metadata": {},
   "source": [
    "Let's also update the data so names are persistent each year even if it's total count is zero for a year. For example, if a unique name like Zyler was use 2 times in 2023 but not once in 2024. There isn't a row stating the total count for Zyler was 0 for 2024. I want to include these rows to help perform trend analysis down the road. The reasoning for this might not be apparent now, but you will see why this is important when we start developing projections for popularities of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05111a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16899750 entries, 0 to 16899749\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   name         object\n",
      " 1   sex          object\n",
      " 2   total_count  int64 \n",
      " 3   year         int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 515.7+ MB\n"
     ]
    }
   ],
   "source": [
    "names_sex = df[['name', 'sex']].drop_duplicates()\n",
    "years = pd.DataFrame({'year': df['year'].drop_duplicates()})\n",
    "\n",
    "# Cross join (cartesian product)\n",
    "all_names = names_sex.assign(key=1).merge(years.assign(key=1), on='key').drop('key', axis=1)\n",
    "all_names['total_count'] = 0\n",
    "\n",
    "# merge the data frames\n",
    "df = pd.concat([df, all_names])\n",
    "\n",
    "# drop duplicates and reset index\n",
    "df = df.drop_duplicates(subset=[\"name\", \"sex\", \"year\"])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c7daf",
   "metadata": {},
   "source": [
    "Let's add a new feature that calculates the relative popularity of a name for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec59377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>total_count</th>\n",
       "      <th>year</th>\n",
       "      <th>popularity_percent</th>\n",
       "      <th>popularity_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liam</td>\n",
       "      <td>M</td>\n",
       "      <td>22164</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noah</td>\n",
       "      <td>M</td>\n",
       "      <td>20337</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oliver</td>\n",
       "      <td>M</td>\n",
       "      <td>15343</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theodore</td>\n",
       "      <td>M</td>\n",
       "      <td>12011</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "      <td>11793</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name sex  total_count  year  popularity_percent  popularity_rank\n",
       "0      Liam   M        22164  2024            0.012921                1\n",
       "1      Noah   M        20337  2024            0.011856                2\n",
       "2    Oliver   M        15343  2024            0.008945                3\n",
       "3  Theodore   M        12011  2024            0.007002                4\n",
       "4     James   M        11793  2024            0.006875                5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the relative popularity of a name for each year\n",
    "df[\"popularity_percent\"] = df.groupby([\"sex\", \"year\"])[\"total_count\"].transform(\"sum\")\n",
    "df[\"popularity_percent\"] = df[\"total_count\"] / df[\"popularity_percent\"]\n",
    "\n",
    "df['popularity_rank'] = df.groupby(['sex', 'year'])['popularity_percent'].rank(method='min', ascending=False).astype(int)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099a2a3",
   "metadata": {},
   "source": [
    "# Create SQLite Database\n",
    "And now we have one giant data frame. Let's save it to a SQLite database and use it for the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f25150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_path = \"data/names.db\"\n",
    "if os.path.exists(db_path)==False:\n",
    "    # create a connection to the database\n",
    "    conn = sqlite3.connect(\"data/names.db\")\n",
    "\n",
    "    # save the data frame to a SQLite database  \n",
    "    df.to_sql(\"names\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # Create indexes for better performance\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE INDEX idx_name ON names(name)')\n",
    "    cursor.execute('CREATE INDEX idx_sex ON names(sex)')\n",
    "    cursor.execute('CREATE INDEX idx_year ON names(year)')\n",
    "    conn.commit()\n",
    "\n",
    "    # close the connection\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
